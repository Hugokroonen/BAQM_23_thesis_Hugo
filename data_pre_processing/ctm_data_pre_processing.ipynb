{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b678542-a6bb-4112-b816-7b9d4753aab7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## README\n",
    "- This notebook cleans and samples from the transaction data to obtain the final modelling datasets. \n",
    "- It should be used twice in the customer segmentation process: once to obtain a sample for fitting the model (y.csv, x.csv, h.csv, products.csv), \n",
    "and once to process the 'to segment' customer set (y_segmentation.csv, x_segmentation.csv, h_segmentation.csv, products_segmentation.csv) to be used in the *CTM-3 Customer Segmentation* notebook\n",
    "\n",
    "The notebook consists of the following three parts.\n",
    "\n",
    "PART 1 - The data pre-processing steps\n",
    "\n",
    "0. Only keep in-store transactions\n",
    "1. Remove 'to-go' and Belgian shops\n",
    "2. Remove 'abusive' bonus cards\n",
    "3. Only keep customers shopping more than X weeks\n",
    "4. Aggregate all products to lowest_level taxonomy\n",
    "5. Take % random sample OR set of customers we want to segment  \n",
    "\n",
    "PART 2 - Resulting datasets\n",
    "\n",
    "(!) For fitting the model: these 4 datasets need to be fully saved as csv - and the header row should be deleted manually for df_y, df_x and df_h - to be used in Python with the following names (!)\n",
    "- **y.csv**: customer_id, basket_id, product_id\n",
    "- **x.csv**: basket_id, trip-specific variables\n",
    "- **h.csv**: customer_id, customer-specific variables \n",
    "- **products.csv**: product_id, lowest_level ((!) must also uploaded to Databricks for later alignment purposes in segmentation (!))\n",
    "\n",
    "(!) For customer segmentation, upload these files to Databricks: (done automatically in the notebook) (!)\n",
    "Now, these files are saved to hive_metastore.default, but perhaps a seperate location would be better.\n",
    "\n",
    "- Renamed y.csv to **y_segmentation.csv** \n",
    "- **customers_segmentation.csv**: customer_id, customerID\n",
    "\n",
    "PART 3 - Descriptive statistics\n",
    "- descriptive statistics for df_y, df_x and df_h\n",
    "\n",
    "\n",
    "The details that need to be changed when using the notebook as data pre-processing step for fitting instead of segmenting:\n",
    "\n",
    "- Timeframe (cmd5, optional)\n",
    "- Sample size (cmd23)\n",
    "- Uncomment line of code that uploads products.csv to Databricks (cmd 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "793779f5-5e0d-4049-a356-2a5867b7a354",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e1dbe1c-1abe-4d1c-be1d-da2c5d97e230",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /CODELIBRARY/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27691a1d-f907-4d97-b192-0696d0d65010",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## (!) Global Parameters - Timeframe (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01498cbe-7164-4385-a025-ffff07d90761",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select desired timeframe of the final sample \n",
    "\n",
    "# For fitting the CTM model in the thesis: 202309 until 202318\n",
    "\n",
    "# For customer segmentation, choose the desired timeframe \n",
    "start_date = get_monday_of_weekkey('202325')\n",
    "end_date = get_monday_of_weekkey('202333')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b21ab2d-49ef-47d3-86aa-63736f895aae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Part 1: Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bb1f439-546d-44b8-af20-0703e986c87a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 0. Only keep in-store transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "558add22-b6c9-45b6-8aa8-7006c96065c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load sales transactions dataset\n",
    "df_sales_transactions = get_table_sales_transactions(start_date, end_date)\n",
    "\n",
    "# Keep only transactions that occurred in-store\n",
    "df_sales_transactions_offline = df_sales_transactions.filter('OnlineFlag = 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8f048a7-ba83-437a-a335-8c8188a0886e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Remove 'to-go' and Belgian shops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fac5894d-f696-4215-9d39-4de36cfbc601",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define function to get relevant stores, with label of what store it is\n",
    "def get_store_banners(min_store_sales_date):\n",
    "  \"\"\"StoreNbr 1200 and 9998 are also located at headquarters, there is no column that allows for filtering\"\"\"\n",
    "  return (\n",
    "    get_table_store()\n",
    "    # Removes headquarters (Zaandam, Coffee company) and DC's. Non-valid StoreNbr's\n",
    "    .filter(~F.col('StoreNbr').between(100, 1000))\n",
    "    .filter(~F.col('StoreNbr').isin(STORES_HSC))\n",
    "    .filter(F.col('StoreSalesEndDt') >= min_store_sales_date)\n",
    "    .filter(F.col('StoreFormatNbr') != -1) # Invalid store format\n",
    "    .filter(F.col('StoreFormatNbr') != 7) # Remove gall stores\n",
    "    .withColumn(\n",
    "    'StoreFormat', F\n",
    "      .when(F.col('StoreNbr').isin(STORES_BE), 'BEL')\n",
    "      .when(F.col('StoreNbr').isin(STORES_TOGO), 'ToGo')\n",
    "      .when(F.col('FranchiseInd') == 'J', 'FR')\n",
    "      .when(F.col('FranchiseInd') == 'N', 'WWM')\n",
    "    )\n",
    "    .select('StoreNbr', 'StoreFormat', 'StoreFormatNbr')\n",
    "  )\n",
    "\n",
    "# Collect store numbers of to-go stores \n",
    "# store_numbers_to_go = get_store_banners('2022-01-01').filter(F.col(\"StoreFormat\") == 'ToGo').select('StoreNbr', 'StoreFormat')\n",
    "store_numbers_to_go = get_store_banners('2022-01-01') \\\n",
    "    .filter((F.col(\"StoreFormat\") == 'ToGo') | (F.col(\"StoreFormat\") == 'BEL')) \\\n",
    "    .select('StoreNbr', 'StoreFormat')\n",
    "\n",
    "# Join with sales transactions to remove transactions from to-go stores\n",
    "df_sales_transactions_without_togo = (\n",
    "  df_sales_transactions_offline\n",
    "  .join(store_numbers_to_go, 'StoreNbr', 'leftanti')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5503cbba-35b3-47bb-9e5d-e2a736a72ee8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2. Remove 'abusive' bonus cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e668445-366c-4604-9cd4-e92ffd8c426d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load abusive bonus cards\n",
    "src_abusive_cardholders = spark.read.format('delta').load('/mnt/sa-datalake-prd/Projects/CustomerTransformation/CustomerData/FixedFeatures/customerid_abusive/') \n",
    "\n",
    "# Filter out transactions with abusive bonus cards\n",
    "df_sales_transactions_without_togo_abusive = (\n",
    "  df_sales_transactions_without_togo\n",
    "  .join(src_abusive_cardholders, 'CustomerID', 'leftanti')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6efd0081-3048-4f54-96ba-1f7050d896de",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3. Only keep customers shopping more than X weeks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e6e876b-c796-4f68-ba39-09fd57d1d3bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set threshold for shopping more than X weeks\n",
    "threshold_amount_of_weeks = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5336d63b-67e0-4fdc-98a0-0cfbd84a0b50",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add a new column to obtain the week number of a shopping trip\n",
    "df_sales_transactions_without_togo_abusive = df_sales_transactions_without_togo_abusive.withColumn('Week', F.weekofyear('TransactionEndDts'))\n",
    "\n",
    "# Calculate the number of weeks each customer made a purchase\n",
    "df_weeks_purchased = df_sales_transactions_without_togo_abusive.groupBy('CustomerID').agg(F.countDistinct('Week').alias('WeeksPurchased'))\n",
    "\n",
    "# Filter out customers with less than 30 weeks of purchases\n",
    "df_loyal_customers = df_weeks_purchased.filter(F.col('WeeksPurchased') >= threshold_amount_of_weeks)\n",
    "\n",
    "# Join back with sales transaction data\n",
    "df_sales_transactions_without_togo_abusive_loyal = (\n",
    "  df_sales_transactions_without_togo_abusive\n",
    "  .join(df_loyal_customers, 'CustomerID', 'inner')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76bf1fc4-b085-4557-9c7e-127947cdb7c1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 4. Aggregate all products to lowest_level taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b77372d0-83ee-4bc6-8f25-2987929ecdb6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get all product taxonomies\n",
    "src_taxonomy = spark.read.csv('/mnt/sa-datalake-prd/Personal/Diederik/Taxonomies/product_taxonomy_paths_longest.csv', header=True, inferSchema=\"true\", sep=';')\n",
    "\n",
    "# Join lowest level taxonomy information with sales transactions\n",
    "df_sales_transactions_without_togo_abusive_loyal_lowest_level = (\n",
    "  df_sales_transactions_without_togo_abusive_loyal\n",
    "  .join(src_taxonomy, 'RetailItemNbr', 'inner')\n",
    ")\n",
    "\n",
    "# Remove products with lowest level null \n",
    "df_sales_transactions_without_togo_abusive_loyal_lowest_level = df_sales_transactions_without_togo_abusive_loyal_lowest_level.dropna(subset=['lowest_level'])\n",
    "\n",
    "df_sales_transactions_without_togo_abusive_loyal_lowest_level.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4e49fd6-267a-4a4a-8b43-409539b57af2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## (!) 5. Sample size (!)\n",
    "- depends on use for fitting or segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22f3a2be-84e6-4801-bb1e-007b7658acfc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set % size of subset\n",
    "\n",
    "# Sample size used for fitting the model in thesis: 0.00014\n",
    "# sample_size = 0.0001\n",
    "\n",
    "# OR \n",
    "\n",
    "# Sample size for customer segmentation (0.5 means 50% of customers)\n",
    "sample_size = 0.2 # For customer segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e3b020d-4e57-4e96-93a7-80948f4f8583",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# First, get a list of all customer IDs that are in the resulting sales transactions dataset\n",
    "df_customer_IDs = df_sales_transactions_without_togo_abusive_loyal_lowest_level.select(\"CustomerID\").distinct()\n",
    "\n",
    "# Select a random sample of of these customer IDs for fitting the model OR use all customers for customer segmentation \n",
    "df_final_sample_IDs = df_customer_IDs.sample(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e11a398b-346e-4093-8686-bd18231b75ac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Part 2: Resulting Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18fd00c5-5d95-458d-ba12-db2e9a30cba2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Sample size\n",
    "- Should contain 125K transactions max. for the CTM model in Python!!!\n",
    "- When using too many transactions for fitting the model, the following error will occur when estimating the model in Python:\n",
    "\n",
    "zsh: segmentation fault  python estimate.py -MODEL CTM -M 3 -N_ITER 2000 -N_SAVE_PER 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19b14c35-7ce1-4b85-b5a9-14c690fe2c07",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Keep only relevant columns\n",
    "df_sales_transactions_without_togo_abusive_loyal_lowest_level = (\n",
    "  df_sales_transactions_without_togo_abusive_loyal_lowest_level\n",
    "  .select('CustomerID', 'RetailItemNbr', 'TransactionID', 'Date', 'EventTimestamp', 'lowest_level', 'QuantityCE', 'SalesGoodsExclDiscountEUR', 'SalesGoodsEUR')\n",
    ")\n",
    "\n",
    "# Final dataset\n",
    "df_final_sample_transactions = (\n",
    "df_sales_transactions_without_togo_abusive_loyal_lowest_level\n",
    ".join(df_final_sample_IDs, 'CustomerID', 'inner')\n",
    ")\n",
    "\n",
    "# Count how many customers in the final sample\n",
    "customers_final_sample = df_final_sample_IDs.agg(F.countDistinct('CustomerID')).collect()[0][0]\n",
    "\n",
    "# Count shopping trips \n",
    "shopping_trips_final_sample = df_final_sample_transactions.agg(F.countDistinct('TransactionID')).collect()[0][0]\n",
    "\n",
    "# Count transactions\n",
    "transactions_final_sample = df_final_sample_transactions.count()\n",
    "\n",
    "# Count unique products\n",
    "different_products_final_sample = df_final_sample_transactions.agg(F.countDistinct('lowest_level')).collect()[0][0] \n",
    "\n",
    "print(\"The final sample contains\", customers_final_sample, \"customers\")\n",
    "print(\"The final sample contains\", shopping_trips_final_sample, \"shopping trips\")\n",
    "print(\"The final sample contains\", transactions_final_sample, \"transactions\")\n",
    "print(\"The final sample contains\", different_products_final_sample, \"different products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac21d7a1-0615-4c5d-b7df-73547aa4aea4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Products dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46ed6b85-b911-4c52-8091-f85f1d0f454d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define a window specification for customer_id\n",
    "customer_window_spec = Window.orderBy(\"CustomerID\")\n",
    "\n",
    "# Add a new column 'customer_id' with new indices for customers ranging from 0 to I-1, ordered by lowest CustomerID values\n",
    "df_final_sample_transactions = df_final_sample_transactions.withColumn(\"customer_id\", F.dense_rank().over(customer_window_spec.orderBy(\"CustomerID\")) - 1)\n",
    "\n",
    "# Define a window specification for basket_id\n",
    "basket_window_spec = Window.orderBy(\"CustomerID\", \"Date\", \"TransactionID\")\n",
    "\n",
    "# Add a new column 'basket_id' with sequential indices for each transaction across all customers \n",
    "df_final_sample_transactions = df_final_sample_transactions.withColumn(\"basket_id\", F.dense_rank().over(basket_window_spec) - 1)\n",
    "\n",
    "# Determine unique RetailItemNbr values and assign their corresponding IDs\n",
    "unique_retail_items = df_final_sample_transactions.select(\"lowest_level\").distinct()\n",
    "unique_retail_items = unique_retail_items.withColumn(\"product_id\", F.row_number().over(Window.orderBy(\"lowest_level\")) - 1)\n",
    "\n",
    "# Join the original DataFrame with the unique_retail_items DataFrame\n",
    "df_final_sample = df_final_sample_transactions.join(\n",
    "    unique_retail_items,\n",
    "    on=\"lowest_level\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df_final_sample.drop('item_id')\n",
    "\n",
    "# Split rows with quantityCE > 1 into multiple rows\n",
    "exploded_df = df_final_sample.withColumn(\"exploded\", F.explode(F.expr(\"split(repeat('1', QuantityCE), '')\")))\n",
    "\n",
    "# Create a new DataFrame with quantityCE = 1 for each exploded row\n",
    "df_final_sample = exploded_df.drop(\"QuantityCE\", \"exploded\")\n",
    "\n",
    "# Create a mapping of product_id to lowest_level to be downloaded later as input for the model \n",
    "df_products = df_final_sample.select('product_id', 'lowest_level').dropDuplicates(['product_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "126281a7-13e7-4fc9-bf48-986d0c60b97a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Customers dataset (only relevant for segmentation (!))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08535ac5-6856-43e0-bf28-5c9262e0b855",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Store a dataframe that maps customer_id - customerID\n",
    "df_customers_segmentation = df_final_sample.select('customer_id', 'CustomerID').dropDuplicates(['customer_id'])\n",
    "\n",
    "# Display result\n",
    "display(df_customers_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d611ce5d-dd9d-40f2-972c-24a5f74461ea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Dataset Y \n",
    "- customer_id, basket_id, product_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60101ad7-4bcc-4fd9-b6b7-68363028af1f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate Y dataset \n",
    "df_y = df_final_sample.select('customer_id', 'basket_id', 'product_id')\n",
    "df_y.display()\n",
    "\n",
    "\n",
    "# Display summary statistics of Y dataset \n",
    "number_of_baskets = df_y.agg(F.max(F.col(\"basket_id\"))).first()[0]\n",
    "number_of_customers = df_y.agg(F.max(F.col(\"customer_id\"))).first()[0]\n",
    "number_of_products = df_y.agg(F.countDistinct(F.col('product_id'))).first()[0]\n",
    "\n",
    "print('number of baskets', number_of_baskets)\n",
    "print('number of customers', number_of_customers)\n",
    "print('number of unique products', number_of_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24c3c9d5-737d-4723-936b-424c0bd35617",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Dataset X\n",
    "- basket_id, trip-specific variables (Promotion, Day of Week, Time of Day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58d7cb55-27ea-4fb0-8581-32e8c2b66d35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add a dummy column 'IsWeekend' indicating whether 'EventTimeStamp' is on a weekend (1 for weekend, 0 for weekday)\n",
    "df_final_sample = df_final_sample.withColumn(\"EventTimestamp\", F.expr(\"to_timestamp(EventTimestamp, 'yyyy-MM-dd''T''HH:mm:ss.SSSZ')\"))\n",
    "df_final_sample = df_final_sample.withColumn(\"IsWeekend\", F.when(F.dayofweek(F.col(\"EventTimestamp\")).isin([1, 7]), 1).otherwise(0))\n",
    "\n",
    "# Add a dummy column After5PM, indicating whether 'EventTimeStamp' is after or before 5pm (1 for evening, 0 for day)\n",
    "df_final_sample = df_final_sample.withColumn(\"After5PM\", F.when(F.hour(F.col(\"EventTimestamp\")) >= 17, 1).otherwise(0))\n",
    "\n",
    "# Add dummy colums for each month \n",
    "df_final_sample = df_final_sample.withColumn(\"January\", F.when(F.month(F.col(\"EventTimestamp\")) == 1, 1).otherwise(0))\n",
    "df_final_sample = df_final_sample.withColumn(\"February\", F.when(F.month(F.col(\"EventTimestamp\")) == 2, 1).otherwise(0))\n",
    "df_final_sample = df_final_sample.withColumn(\"March\", F.when(F.month(F.col(\"EventTimestamp\")) == 3, 1).otherwise(0))\n",
    "df_final_sample = df_final_sample.withColumn(\"April\", F.when(F.month(F.col(\"EventTimestamp\")) == 4, 1).otherwise(0))\n",
    "df_final_sample = df_final_sample.withColumn(\"May\", F.when(F.month(F.col(\"EventTimestamp\")) == 5, 1).otherwise(0))\n",
    "df_final_sample = df_final_sample.withColumn(\"June\", F.when(F.month(F.col(\"EventTimestamp\")) == 6, 1).otherwise(0))\n",
    "df_final_sample = df_final_sample.withColumn(\"July\", F.when(F.month(F.col(\"EventTimestamp\")) == 7, 1).otherwise(0))\n",
    "df_final_sample = df_final_sample.withColumn(\"August\", F.when(F.month(F.col(\"EventTimestamp\")) == 8, 1).otherwise(0))\n",
    "df_final_sample = df_final_sample.withColumn(\"September\", F.when(F.month(F.col(\"EventTimestamp\")) == 9, 1).otherwise(0))\n",
    "df_final_sample = df_final_sample.withColumn(\"October\", F.when(F.month(F.col(\"EventTimestamp\")) == 10, 1).otherwise(0))\n",
    "df_final_sample = df_final_sample.withColumn(\"November\", F.when(F.month(F.col(\"EventTimestamp\")) == 11, 1).otherwise(0))\n",
    "df_final_sample = df_final_sample.withColumn(\"December\", F.when(F.month(F.col(\"EventTimestamp\")) == 12, 1).otherwise(0))\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df_final_sample.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8a985ed-a825-43ca-acee-7da0ea712ac4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the total discount for each basket\n",
    "df_discount = df_final_sample.groupBy('basket_id').agg(\n",
    "    F.sum(F.col('SalesGoodsExclDiscountEUR') - F.col('SalesGoodsEUR')).alias('total_discount'),\n",
    "    F.sum('SalesGoodsExclDiscountEUR').alias('total_sales_excl_discount')\n",
    ")\n",
    "\n",
    "# Calculate the percentage discount of the total basket value \n",
    "window_spec = Window.partitionBy('basket_id')\n",
    "df_discount = df_discount.withColumn(\n",
    "    'basket_discount_percentage',\n",
    "    (F.col('total_discount') / F.col('total_sales_excl_discount'))\n",
    ")\n",
    "\n",
    "# Join the discount DataFrame back to the original DataFrame\n",
    "df_final_sample_transactions_final_discounts = df_final_sample.join(df_discount, on='basket_id', how='left')\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df_final_sample_transactions_final_discounts.select('customer_id', 'basket_id', 'product_id', 'SalesGoodsExclDiscountEUR', 'SalesGoodsEUR', 'total_discount', 'total_sales_excl_discount', 'basket_discount_percentage', 'IsWeekend', 'After5PM', 'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December').display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dff0eb3-06dc-47e0-bf79-8340854ce8e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display the final X dataset \n",
    "df_x = df_final_sample_transactions_final_discounts.select('basket_id', 'basket_discount_percentage', 'IsWeekend', 'After5PM', 'January', 'February', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December')\n",
    "df_x = df_x.drop_duplicates(subset=['basket_id'])\n",
    "display(df_x)\n",
    "\n",
    "# Display the number of baskets \n",
    "number_of_baskets = df_x.agg(F.max(F.col(\"basket_id\"))).first()[0]\n",
    "print('number of baskets', number_of_baskets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c6c3347-935d-4def-bd4c-a093468a18b8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Dataset H\n",
    "- customer_id, customer-specific variables (Age, Location) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39bb9bb4-8e2b-413b-a6ea-f0fe7a875c24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load customer master table \n",
    "src_customer_master = get_table_customer_master()\n",
    "\n",
    "# Join the final dataset with the customer_master table, to find the Membernbr for each offline customer \n",
    "df_final_transactions_with_member_numbers = (\n",
    "df_final_sample\n",
    ".join(src_customer_master, 'CustomerID', 'left')\n",
    ")\n",
    "\n",
    "# Load customer demographics table \n",
    "df_customer_demographics = get_table_customers_privacylocker_thor()\n",
    "\n",
    "# Using each customer's member number, add available customer Age and Location information to each customer \n",
    "df_customer_demographics_offline = (\n",
    "  df_final_transactions_with_member_numbers\n",
    "  .join(df_customer_demographics, 'MemberNbr', 'left')\n",
    "  .select('customer_id', 'CityName', 'DateOfBirth')\n",
    ")\n",
    "\n",
    "df_customer_demographics_offline = df_customer_demographics_offline.drop_duplicates(subset=['customer_id'])\n",
    "\n",
    "# Display customer information (Location, Age)\n",
    "df_customer_demographics_offline.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91f80c48-f692-4bf1-9189-c559e50d77d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create dummies for age \n",
    "df_ages = df_customer_demographics_offline.withColumn('Age', (F.current_date() - F.col('DateOfBirth')).cast('integer') / 365)\n",
    "df_ages = df_ages.withColumn('UnknownAge', F.when(F.col('DateOfBirth').isNull(), 1).otherwise(0))\n",
    "df_ages = df_ages.withColumn('Age_0_25', F.when((F.col('Age') >= 0) & (F.col('Age') <= 25), 1).otherwise(0))\n",
    "df_ages = df_ages.withColumn('Age_25_35', F.when((F.col('Age') >= 25) & (F.col('Age') <= 35), 1).otherwise(0))\n",
    "df_ages = df_ages.withColumn('Age_35_45', F.when((F.col('Age') > 35) & (F.col('Age') <= 45), 1).otherwise(0))\n",
    "df_ages = df_ages.withColumn('Age_45_55', F.when((F.col('Age') > 45) & (F.col('Age') <= 55), 1).otherwise(0))\n",
    "df_ages = df_ages.withColumn('Age_55_65', F.when((F.col('Age') > 55) & (F.col('Age') <= 65), 1).otherwise(0))\n",
    "df_ages = df_ages.withColumn('Age_65_plus', F.when(F.col('Age') > 65, 1).otherwise(0))\n",
    "df_ages = df_ages.drop('Age')\n",
    "\n",
    "# Create dummy for large city or not. A large city is a city with more than 250.000 habitants \n",
    "cities = ['AMSTERDAM', 'ROTTERDAM', \"'S-GRAVENHAGE\", 'UTRECHT'] # Cities with more than 250.000 habitants \n",
    "\n",
    "df_ages_and_cities = df_ages.withColumn('IsCity', F.when(F.col('CityName').isin(cities), 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68ea364a-a3cc-452c-8668-8b4c2f523584",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display the number of customers in the sample and structure the H dataset\n",
    "df_h = df_ages_and_cities.select('customer_id', 'UnknownAge', 'Age_0_25','Age_25_35', 'Age_35_45', 'Age_55_65', 'Age_65_plus', 'IsCity')\n",
    "number_of_customers = df_y.agg(F.max(F.col(\"customer_id\"))).first()[0]\n",
    "print(' number of customers', number_of_customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2608423-3261-45d5-8921-c94cc755272c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## In case of data pre-processing for fitting the CTM model, download these files:\n",
    "## (!) Final datasets - download as CSV (all rows) as input for CTM model in Python (!) \n",
    "\n",
    "- Make sure to delete the column headers (manually) from y.csv, x.csv and h.csv, otherwise you will get a Python error of this kind:\n",
    "\n",
    "ValueError: could not convert string 'basket_discount_percentage' to float64 at row 0, column 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dba1cae3-4426-4815-8a46-5443b8200423",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# (!) download df_y as csv (!) \n",
    "df_y.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c268f8c6-2ad0-4d98-b3fe-dce07488dfdd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# (!) download df_x as csv (!) \n",
    "df_x.select('basket_discount_percentage', 'IsWeekend', 'After5PM').display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7624431-28dd-40f5-9707-1ff0fa533d17",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# (!) download df_h as csv (!) \n",
    "df_h.drop('customer_id').display(header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21c0d65f-86aa-43f8-8951-fd831e22ff27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# (!) download df_products as csv (!)\n",
    "df_products.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a0fa5b3-1059-4e1c-ba33-f52a27ad5f38",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### (!) comment out following cell when used to generate segmenting set (!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cc2939c-f99e-41ae-9c35-bc28fd0b1f92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write df_products to Databricks, must be done ONLY if this notebook is used for fitting the model\n",
    "# Because we need to save the product id - lowest level alignment to be used in customer segmentation part \n",
    "\n",
    "# WHEN USED FOR GENERATING A 'TO SEGMENT' SET, THE FOLLOWING LINE MUST BE COMMENTED OUT! \n",
    "\n",
    "# df_products.write.mode(\"overwrite\").option('overwriteSchema', True).saveAsTable('products')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a80135d-d449-472a-8c92-fc0ad30fab17",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## In case of data pre-processing for customer segmentation, write these files to Databricks:\n",
    "## (!) Final datasets - upload to Databricks for customer segmentation (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "563fea42-58cd-4fd9-ac74-75f8e7b35ae7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We need to align the product_id - lowest_level mapping when fitting the model with the mapping used in segmentation. \n",
    "# By running this cell, we ensure that the products in y_segmentation get the same product_id's as in the fitted model. That is needed to ensure that the counts_phi values\n",
    "# correspond to the correct products. \n",
    "\n",
    "# Obtain the df_products that was used when fitting the model (from above or manually upload an earlier products file to Databricks)\n",
    "df_products = table('default.products') \n",
    "\n",
    "# Join the to segment customer sample with the product_id - lowest_level mapping from the fitted model \n",
    "df_final_sample = df_final_sample.withColumnRenamed(\"product_id\", \"product_id_segmentation\")\n",
    "df_final_sample_with_original_product_ids = df_final_sample.join(df_products, 'lowest_level', 'left')\n",
    "\n",
    "# Filter out lowest levels that did not exist when fitting the model \n",
    "df_final_sample_segmentation = df_final_sample_with_original_product_ids.filter(F.col('product_id').isNotNull())\n",
    "\n",
    "# Display the updated sample, with the same lowest_level - product_id mapping as when fitting the model\n",
    "display(df_final_sample_segmentation)\n",
    "\n",
    "# Create y_segmentation with the updated product id's\n",
    "df_y_segmentation = df_final_sample_segmentation.select('customer_id', 'basket_id', 'product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9989b920-f861-4875-9166-1ac0cc999512",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# (!) Upload df_y_segmentation to Databricks (!)\n",
    "df_y_segmentation.write.mode(\"overwrite\").option('overwriteSchema', True).saveAsTable('y_segmentation')\n",
    "df_y_segmentation.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65b4729b-c4f6-4c1b-ae0e-2f8480cbfcec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# (!) Upload df_customers_segmentation to Databricks (!)\n",
    "# So that in the final results, we can retrieve the original customer IDs of 'to-segment' customers \n",
    "df_customers_segmentation.write.mode(\"overwrite\").option('overwriteSchema', True).saveAsTable('customers_segmentation')\n",
    "df_customers_segmentation.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce1dbf0d-5180-474e-83ae-761e251bafad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Part 3: Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6499f3d-a264-4c63-887a-a9cb83ea8903",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Descriptive statistics y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "857adbea-8867-4812-a16a-0fc114075fc4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print('number of baskets', number_of_baskets)\n",
    "print('number of customers', number_of_customers)\n",
    "print('number of unique products', number_of_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9437a6cf-9a6e-4579-bfe6-94c8bf951ad9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Descriptive statistics x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e07761b3-738d-4738-b163-df0de1733fa4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compute the summary statistics\n",
    "summary_df = df_x.agg(\n",
    "    F.avg(F.col('basket_discount_percentage')).alias('Average_discount'),\n",
    "    F.sum(F.col('IsWeekend')).alias('IsWeekend'),\n",
    "    F.sum(F.col('After5PM')).alias('After5PM'),\n",
    "    F.sum(F.col('January')).alias('January'),\n",
    "    F.sum(F.col('February')).alias('February'),\n",
    "    F.sum(F.col('April')).alias('April'),\n",
    "    F.sum(F.col('May')).alias('May'),\n",
    "    F.sum(F.col('June')).alias('June'),\n",
    "    F.sum(F.col('July')).alias('July'),\n",
    "    F.sum(F.col('August')).alias('August'),\n",
    "    F.sum(F.col('September')).alias('September'),\n",
    "    F.sum(F.col('October')).alias('October'),\n",
    "    F.sum(F.col('November')).alias('November'),\n",
    "    F.sum(F.col('December')).alias('December')\n",
    ")\n",
    "\n",
    "# Compute the frequency and percentage of 1's for dummy variables\n",
    "dummy_cols = ['IsWeekend', 'After5PM', 'January', 'February', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "for col_name in dummy_cols:\n",
    "    total_count = df_x.count()\n",
    "    sum_col = df_x.agg(F.sum(F.col(col_name))).collect()[0][0]\n",
    "    percentage = (sum_col / total_count) * 100\n",
    "    summary_df = summary_df.withColumn(col_name + '_Frequency', F.lit(sum_col))\\\n",
    "                           .withColumn(col_name + '_Percentage', F.lit(percentage))\n",
    "\n",
    "# Drop the columns not needed in the final table\n",
    "summary_df = summary_df.drop('basket_id', *dummy_cols)\n",
    "\n",
    "# Show the final table\n",
    "summary_df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b751833e-890d-42e5-b069-4d9569d8b6ef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Descriptive statistics h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07bac123-1b20-4a73-a6c0-3e924a28c977",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compute the summary statistics\n",
    "summary_df_h = df_h.agg(\n",
    "    F.sum(F.col('UnknownAge')).alias('UnknownAge_Frequency'),\n",
    "    F.sum(F.col('Age_0_25')).alias('Age_0_25_Frequency'),\n",
    "    F.sum(F.col('Age_25_35')).alias('Age_25_35_Frequency'),\n",
    "    F.sum(F.col('Age_35_45')).alias('Age_35_45_Frequency'),\n",
    "    F.sum(F.col('Age_55_65')).alias('Age_55_65_Frequency'),\n",
    "    F.sum(F.col('Age_65_plus')).alias('Age_65_plus_Frequency'),\n",
    "    F.sum(F.col('IsCity')).alias('IsCity_Frequency')\n",
    ")\n",
    "\n",
    "# Compute the percentage of 1's for dummy variables\n",
    "dummy_cols_h = ['UnknownAge', 'Age_0_25', 'Age_25_35', 'Age_35_45', 'Age_55_65', 'Age_65_plus', 'IsCity']\n",
    "\n",
    "for col_name in dummy_cols_h:\n",
    "    total_count = df_h.count()\n",
    "    sum_col = df_h.agg(F.sum(F.col(col_name))).collect()[0][0]\n",
    "    percentage = (sum_col / total_count) * 100\n",
    "    summary_df_h = summary_df_h.withColumn(col_name + '_Percentage', F.lit(percentage))\n",
    "\n",
    "# Show the final table for df_h\n",
    "summary_df_h.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "CTM Data Pre-Processing",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
